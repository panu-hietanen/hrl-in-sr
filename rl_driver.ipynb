{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from libs.srenv import SREnv\n",
    "from agents.rlagent import DQNAgent, ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = {\n",
    "    '+': 2,\n",
    "    '-': 2,\n",
    "    '*': 2,\n",
    "    '/': 2,\n",
    "    # 'sin': 1,\n",
    "    # 'cos': 1,\n",
    "    'C': 0  # Placeholder for constants\n",
    "}\n",
    "\n",
    "# Create your data and target tensors\n",
    "n_samples = 1000\n",
    "n_vars = 1\n",
    "\n",
    "for i in range(n_vars):\n",
    "    var_name = f'X{i}'\n",
    "    library[var_name] = 0\n",
    "\n",
    "# X0 = torch.randn(-10, 10, n_samples)\n",
    "# X1 = torch.linspace(-10, 10, n_samples)\n",
    "data = torch.randn([n_vars, n_samples])  # Shape: (n_vars, n_samples)\n",
    "target = 2 * data[0] + 5\n",
    "\n",
    "# Initialize the environment\n",
    "max_depth = 10\n",
    "env = SREnv(library=library, data=data, target=target, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary\n",
    "vocab = list(library.keys()) + ['PAD']\n",
    "symbol_to_index = {symbol: idx for idx, symbol in enumerate(vocab)}\n",
    "index_to_symbol = {idx: symbol for symbol, idx in symbol_to_index.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Maximum sequence length\n",
    "max_seq_length = max_depth\n",
    "\n",
    "def encode_state(state):\n",
    "    # Convert symbols to indices\n",
    "    state_indices = [symbol_to_index[symbol] for symbol in state]\n",
    "    # Pad sequence\n",
    "    if len(state_indices) < max_seq_length:\n",
    "        state_indices += [symbol_to_index['PAD']] * (max_seq_length - len(state_indices))\n",
    "    else:\n",
    "        state_indices = state_indices[:max_seq_length]\n",
    "    return torch.tensor(state_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_symbols = list(library.keys())\n",
    "action_size = len(action_symbols)\n",
    "symbol_to_action_idx = {symbol: idx for idx, symbol in enumerate(action_symbols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '-', '*', '/', 'C', 'X0']\n"
     ]
    }
   ],
   "source": [
    "print(action_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_batches = 100\n",
    "num_episodes_per_batch = 10\n",
    "batch_quantile = 0.2\n",
    "batch_size = 250\n",
    "gamma = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.1\n",
    "epsilon_decay = 0.95\n",
    "target_update = num_batches / 10\n",
    "memory_capacity = max_seq_length * num_episodes_per_batch * num_batches\n",
    "batch_eval = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0.0 failed, Total Reward: -1\n",
      "Episode 0.1 failed, Total Reward: -1\n",
      "Episode 0.2 failed, Total Reward: -1\n",
      "Episode 0.3 failed, Total Reward: -1\n",
      "Episode 0.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 0.5 completed, Total Reward: 0.0360051691532135\n",
      "Episode 0.6 completed, Total Reward: 0.09954887628555298\n",
      "Episode 0.7 failed, Total Reward: -1\n",
      "Episode 0.8 failed, Total Reward: -1\n",
      "Episode 0.9 completed, Total Reward: 0.19919762015342712\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 1.0 failed, Total Reward: -1\n",
      "Episode 1.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 1.2 failed, Total Reward: -1\n",
      "Episode 1.3 failed, Total Reward: -1\n",
      "Episode 1.4 failed, Total Reward: -1\n",
      "Episode 1.5 failed, Total Reward: -1\n",
      "Episode 1.6 failed, Total Reward: -1\n",
      "Episode 1.7 failed, Total Reward: -1\n",
      "Episode 1.8 failed, Total Reward: -1\n",
      "Episode 1.9 failed, Total Reward: -1\n",
      "Episode 2.0 failed, Total Reward: -1\n",
      "Episode 2.1 failed, Total Reward: -1\n",
      "Episode 2.2 failed, Total Reward: -1\n",
      "Episode 2.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 2.4 failed, Total Reward: -1\n",
      "Episode 2.5 failed, Total Reward: -1\n",
      "Episode 2.6 failed, Total Reward: -1\n",
      "Episode 2.7 completed, Total Reward: 0.19919760525226593\n",
      "Episode 2.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 2.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 3.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 3.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 3.2 completed, Total Reward: 0.19919760525226593\n",
      "Episode 3.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 3.4 failed, Total Reward: -1\n",
      "Episode 3.5 failed, Total Reward: -1\n",
      "Episode 3.6 failed, Total Reward: -1\n",
      "Episode 3.7 failed, Total Reward: -1\n",
      "Episode 3.8 failed, Total Reward: -1\n",
      "Episode 3.9 completed, Total Reward: 0.0360051691532135\n",
      "Episode 4.0 failed, Total Reward: -1\n",
      "Episode 4.1 failed, Total Reward: -1\n",
      "Episode 4.2 failed, Total Reward: -1\n",
      "Episode 4.3 failed, Total Reward: -1\n",
      "Episode 4.4 failed, Total Reward: -1\n",
      "Episode 4.5 failed, Total Reward: -1\n",
      "Episode 4.6 failed, Total Reward: -1\n",
      "Episode 4.7 failed, Total Reward: -1\n",
      "Episode 4.8 failed, Total Reward: -1\n",
      "Episode 4.9 failed, Total Reward: -1\n",
      "Episode 5.0 failed, Total Reward: -1\n",
      "Episode 5.1 failed, Total Reward: -1\n",
      "Episode 5.2 failed, Total Reward: -1\n",
      "Episode 5.3 failed, Total Reward: -1\n",
      "Episode 5.4 completed, Total Reward: 0.0360051691532135\n",
      "Episode 5.5 failed, Total Reward: -1\n",
      "Episode 5.6 failed, Total Reward: -1\n",
      "Episode 5.7 failed, Total Reward: -1\n",
      "Episode 5.8 failed, Total Reward: -1\n",
      "Episode 5.9 failed, Total Reward: -1\n",
      "Episode 6.0 failed, Total Reward: -1\n",
      "Episode 6.1 failed, Total Reward: -1\n",
      "Episode 6.2 failed, Total Reward: -1\n",
      "Episode 6.3 failed, Total Reward: -1\n",
      "Episode 6.4 failed, Total Reward: -1\n",
      "Episode 6.5 failed, Total Reward: -1\n",
      "Episode 6.6 failed, Total Reward: -1\n",
      "Episode 6.7 failed, Total Reward: -1\n",
      "Episode 6.8 failed, Total Reward: -1\n",
      "Episode 6.9 failed, Total Reward: -1\n",
      "Episode 7.0 failed, Total Reward: -1\n",
      "Episode 7.1 failed, Total Reward: -1\n",
      "Episode 7.2 completed, Total Reward: 0.19919760525226593\n",
      "Episode 7.3 failed, Total Reward: -1\n",
      "Episode 7.4 failed, Total Reward: -1\n",
      "Episode 7.5 failed, Total Reward: -1\n",
      "Episode 7.6 failed, Total Reward: -1\n",
      "Episode 7.7 failed, Total Reward: -1\n",
      "Episode 7.8 failed, Total Reward: -1\n",
      "Episode 7.9 failed, Total Reward: -1\n",
      "Episode 8.0 failed, Total Reward: -1\n",
      "Episode 8.1 failed, Total Reward: -1\n",
      "Episode 8.2 failed, Total Reward: -1\n",
      "Episode 8.3 failed, Total Reward: -1\n",
      "Episode 8.4 failed, Total Reward: -1\n",
      "Episode 8.5 failed, Total Reward: -1\n",
      "Episode 8.6 failed, Total Reward: -1\n",
      "Episode 8.7 failed, Total Reward: -1\n",
      "Episode 8.8 failed, Total Reward: -1\n",
      "Episode 8.9 failed, Total Reward: -1\n",
      "Episode 9.0 failed, Total Reward: -1\n",
      "Episode 9.1 failed, Total Reward: -1\n",
      "Episode 9.2 failed, Total Reward: -1\n",
      "Episode 9.3 failed, Total Reward: -1\n",
      "Episode 9.4 failed, Total Reward: -1\n",
      "Episode 9.5 failed, Total Reward: -1\n",
      "Episode 9.6 failed, Total Reward: -1\n",
      "Episode 9.7 failed, Total Reward: -1\n",
      "Episode 9.8 failed, Total Reward: -1\n",
      "Episode 9.9 failed, Total Reward: -1\n",
      "Episode 10.0 failed, Total Reward: -1\n",
      "Episode 10.1 failed, Total Reward: -1\n",
      "Episode 10.2 failed, Total Reward: -1\n",
      "Episode 10.3 failed, Total Reward: -1\n",
      "Episode 10.4 failed, Total Reward: -1\n",
      "Episode 10.5 failed, Total Reward: -1\n",
      "Episode 10.6 failed, Total Reward: -1\n",
      "Episode 10.7 failed, Total Reward: -1\n",
      "Episode 10.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 10.9 failed, Total Reward: -1\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 11.0 failed, Total Reward: -1\n",
      "Episode 11.1 failed, Total Reward: -1\n",
      "Episode 11.2 failed, Total Reward: -1\n",
      "Episode 11.3 failed, Total Reward: -1\n",
      "Episode 11.4 failed, Total Reward: -1\n",
      "Episode 11.5 failed, Total Reward: -1\n",
      "Episode 11.6 failed, Total Reward: -1\n",
      "Episode 11.7 failed, Total Reward: -1\n",
      "Episode 11.8 failed, Total Reward: -1\n",
      "Episode 11.9 failed, Total Reward: -1\n",
      "Episode 12.0 failed, Total Reward: -1\n",
      "Episode 12.1 failed, Total Reward: -1\n",
      "Episode 12.2 failed, Total Reward: -1\n",
      "Episode 12.3 failed, Total Reward: -1\n",
      "Episode 12.4 failed, Total Reward: -1\n",
      "Episode 12.5 failed, Total Reward: -1\n",
      "Episode 12.6 completed, Total Reward: 0.03867567703127861\n",
      "Episode 12.7 failed, Total Reward: -1\n",
      "Episode 12.8 completed, Total Reward: 0.4987444281578064\n",
      "Episode 12.9 completed, Total Reward: 0.4987444281578064\n",
      "Episode 13.0 failed, Total Reward: -1\n",
      "Episode 13.1 failed, Total Reward: -1\n",
      "Episode 13.2 failed, Total Reward: -1\n",
      "Episode 13.3 failed, Total Reward: -1\n",
      "Episode 13.4 failed, Total Reward: -1\n",
      "Episode 13.5 completed, Total Reward: 0.05854608118534088\n",
      "Episode 13.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 13.7 completed, Total Reward: 0.0360051691532135\n",
      "Episode 13.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 13.9 completed, Total Reward: 0.03867567703127861\n",
      "Episode 14.0 completed, Total Reward: 1.0\n",
      "Episode 14.1 completed, Total Reward: 0.038276225328445435\n",
      "Episode 14.2 failed, Total Reward: -1\n",
      "Episode 14.3 completed, Total Reward: 0.01815340667963028\n",
      "Episode 14.4 completed, Total Reward: 0.03867567330598831\n",
      "Episode 14.5 completed, Total Reward: 0.021937496960163116\n",
      "Episode 14.6 completed, Total Reward: 0.02674761414527893\n",
      "Episode 14.7 completed, Total Reward: 0.0360051691532135\n",
      "Episode 14.8 completed, Total Reward: 0.0360051691532135\n",
      "Episode 14.9 completed, Total Reward: 0.0360051691532135\n",
      "Episode 15.0 completed, Total Reward: 0.0360051691532135\n",
      "Episode 15.1 completed, Total Reward: 0.03846153989434242\n",
      "Episode 15.2 completed, Total Reward: 0.0360051691532135\n",
      "Episode 15.3 completed, Total Reward: 0.03167634457349777\n",
      "Episode 15.4 completed, Total Reward: 0.022111449390649796\n",
      "Episode 15.5 completed, Total Reward: 0.01815340667963028\n",
      "Episode 15.6 completed, Total Reward: 0.021937496960163116\n",
      "Episode 15.7 completed, Total Reward: 0.01815340667963028\n",
      "Episode 15.8 completed, Total Reward: 0.02047322690486908\n",
      "Episode 15.9 completed, Total Reward: 0.03867567703127861\n",
      "Episode 16.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 16.6 completed, Total Reward: 0.4987444281578064\n",
      "Episode 16.7 completed, Total Reward: 0.09954887628555298\n",
      "Episode 16.8 failed, Total Reward: -1\n",
      "Episode 16.9 failed, Total Reward: -1\n",
      "Episode 17.0 completed, Total Reward: 0.03867567703127861\n",
      "Episode 17.1 completed, Total Reward: 0.04691198095679283\n",
      "Episode 17.2 completed, Total Reward: 0.03867567703127861\n",
      "Episode 17.3 completed, Total Reward: 0.03867567703127861\n",
      "Episode 17.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 17.5 completed, Total Reward: 0.06962113082408905\n",
      "Episode 17.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 17.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 17.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 17.9 completed, Total Reward: 0.19919760525226593\n",
      "Episode 18.0 completed, Total Reward: 0.09954887628555298\n",
      "Episode 18.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 18.2 completed, Total Reward: 0.19919760525226593\n",
      "Episode 18.3 completed, Total Reward: 0.03867567703127861\n",
      "Episode 18.4 completed, Total Reward: 0.03867567703127861\n",
      "Episode 18.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 18.6 completed, Total Reward: 0.03867567703127861\n",
      "Episode 18.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 18.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 18.9 completed, Total Reward: 0.19919760525226593\n",
      "Episode 19.0 completed, Total Reward: 0.03167479857802391\n",
      "Episode 19.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 19.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.7 completed, Total Reward: 0.19919760525226593\n",
      "Episode 19.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 19.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 20.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 20.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 20.2 completed, Total Reward: 0.03167634457349777\n",
      "Episode 20.3 completed, Total Reward: 0.03177650645375252\n",
      "Episode 20.4 failed, Total Reward: -1\n",
      "Episode 20.5 failed, Total Reward: -1\n",
      "Episode 20.6 failed, Total Reward: -1\n",
      "Episode 20.7 failed, Total Reward: -1\n",
      "Episode 20.8 failed, Total Reward: -1\n",
      "Episode 20.9 completed, Total Reward: 0.19919762015342712\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 21.0 failed, Total Reward: -1\n",
      "Episode 21.1 completed, Total Reward: 0.03170948475599289\n",
      "Episode 21.2 completed, Total Reward: 0.03167634457349777\n",
      "Episode 21.3 completed, Total Reward: 0.031691618263721466\n",
      "Episode 21.4 completed, Total Reward: 0.031661245971918106\n",
      "Episode 21.5 completed, Total Reward: 0.13668496906757355\n",
      "Episode 21.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 21.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 21.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 21.9 completed, Total Reward: 0.03398565202951431\n",
      "Episode 22.0 completed, Total Reward: 0.031646162271499634\n",
      "Episode 22.1 completed, Total Reward: 0.036003340035676956\n",
      "Episode 22.2 completed, Total Reward: 0.031691618263721466\n",
      "Episode 22.3 completed, Total Reward: 0.04504416137933731\n",
      "Episode 22.4 completed, Total Reward: 0.031691618263721466\n",
      "Episode 22.5 failed, Total Reward: -1\n",
      "Episode 22.6 failed, Total Reward: -1\n",
      "Episode 22.7 completed, Total Reward: 0.03177650645375252\n",
      "Episode 22.8 completed, Total Reward: 0.03177650645375252\n",
      "Episode 22.9 completed, Total Reward: 0.03177650645375252\n",
      "Episode 23.0 completed, Total Reward: 0.03171812370419502\n",
      "Episode 23.1 completed, Total Reward: 0.03171812370419502\n",
      "Episode 23.2 completed, Total Reward: 0.03171812370419502\n",
      "Episode 23.3 completed, Total Reward: 0.031691618263721466\n",
      "Episode 23.4 completed, Total Reward: 0.03177650645375252\n",
      "Episode 23.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 23.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 23.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 23.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 23.9 completed, Total Reward: 0.031691618263721466\n",
      "Episode 24.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 24.1 completed, Total Reward: 0.19919760525226593\n",
      "Episode 24.2 failed, Total Reward: -1\n",
      "Episode 24.3 completed, Total Reward: 0.0360051691532135\n",
      "Episode 24.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 24.5 completed, Total Reward: 0.4987443685531616\n",
      "Episode 24.6 failed, Total Reward: -1\n",
      "Episode 24.7 failed, Total Reward: -1\n",
      "Episode 24.8 completed, Total Reward: 0.031691618263721466\n",
      "Episode 24.9 failed, Total Reward: -1\n",
      "Episode 25.0 completed, Total Reward: 0.19919760525226593\n",
      "Episode 25.1 failed, Total Reward: -1\n",
      "Episode 25.2 completed, Total Reward: 0.03177650645375252\n",
      "Episode 25.3 completed, Total Reward: 0.03177650272846222\n",
      "Episode 25.4 completed, Total Reward: 0.031691618263721466\n",
      "Episode 25.5 completed, Total Reward: 0.03177650645375252\n",
      "Episode 25.6 failed, Total Reward: -1\n",
      "Episode 25.7 failed, Total Reward: -1\n",
      "Episode 25.8 failed, Total Reward: -1\n",
      "Episode 25.9 failed, Total Reward: -1\n",
      "Episode 26.0 failed, Total Reward: -1\n",
      "Episode 26.1 failed, Total Reward: -1\n",
      "Episode 26.2 failed, Total Reward: -1\n",
      "Episode 26.3 completed, Total Reward: 0.03212903067469597\n",
      "Episode 26.4 failed, Total Reward: -1\n",
      "Episode 26.5 failed, Total Reward: -1\n",
      "Episode 26.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 26.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 26.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 26.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 27.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 27.1 failed, Total Reward: -1\n",
      "Episode 27.2 failed, Total Reward: -1\n",
      "Episode 27.3 failed, Total Reward: -1\n",
      "Episode 27.4 completed, Total Reward: 0.03167668730020523\n",
      "Episode 27.5 failed, Total Reward: -1\n",
      "Episode 27.6 failed, Total Reward: -1\n",
      "Episode 27.7 completed, Total Reward: 0.0360051691532135\n",
      "Episode 27.8 failed, Total Reward: -1\n",
      "Episode 27.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 28.0 completed, Total Reward: 0.031691618263721466\n",
      "Episode 28.1 failed, Total Reward: -1\n",
      "Episode 28.2 failed, Total Reward: -1\n",
      "Episode 28.3 completed, Total Reward: 0.0360051691532135\n",
      "Episode 28.4 completed, Total Reward: 0.0360051691532135\n",
      "Episode 28.5 completed, Total Reward: 0.0360051691532135\n",
      "Episode 28.6 completed, Total Reward: 0.0360051691532135\n",
      "Episode 28.7 failed, Total Reward: -1\n",
      "Episode 28.8 failed, Total Reward: -1\n",
      "Episode 28.9 failed, Total Reward: -1\n",
      "Episode 29.0 failed, Total Reward: -1\n",
      "Episode 29.1 failed, Total Reward: -1\n",
      "Episode 29.2 failed, Total Reward: -1\n",
      "Episode 29.3 failed, Total Reward: -1\n",
      "Episode 29.4 completed, Total Reward: 0.0360051691532135\n",
      "Episode 29.5 completed, Total Reward: 0.031611114740371704\n",
      "Episode 29.6 failed, Total Reward: -1\n",
      "Episode 29.7 failed, Total Reward: -1\n",
      "Episode 29.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 29.9 failed, Total Reward: -1\n",
      "Episode 30.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 30.1 completed, Total Reward: 0.19919760525226593\n",
      "Episode 30.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 30.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 30.4 completed, Total Reward: 0.0360051691532135\n",
      "Episode 30.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 30.6 failed, Total Reward: -1\n",
      "Episode 30.7 failed, Total Reward: -1\n",
      "Episode 30.8 failed, Total Reward: -1\n",
      "Episode 30.9 failed, Total Reward: -1\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 31.0 failed, Total Reward: -1\n",
      "Episode 31.1 failed, Total Reward: -1\n",
      "Episode 31.2 failed, Total Reward: -1\n",
      "Episode 31.3 failed, Total Reward: -1\n",
      "Episode 31.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 31.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 31.6 completed, Total Reward: 0.4987443685531616\n",
      "Episode 31.7 completed, Total Reward: 0.19919760525226593\n",
      "Episode 31.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 31.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 32.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 32.1 failed, Total Reward: -1\n",
      "Episode 32.2 failed, Total Reward: -1\n",
      "Episode 32.3 failed, Total Reward: -1\n",
      "Episode 32.4 failed, Total Reward: -1\n",
      "Episode 32.5 failed, Total Reward: -1\n",
      "Episode 32.6 failed, Total Reward: -1\n",
      "Episode 32.7 completed, Total Reward: 0.03941068798303604\n",
      "Episode 32.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 32.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 33.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 33.1 completed, Total Reward: 0.4987443685531616\n",
      "Episode 33.2 failed, Total Reward: -1\n",
      "Episode 33.3 failed, Total Reward: -1\n",
      "Episode 33.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 33.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 33.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 33.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 33.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 33.9 completed, Total Reward: 0.0360051691532135\n",
      "Episode 34.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 34.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 34.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 34.3 completed, Total Reward: 0.19919760525226593\n",
      "Episode 34.4 completed, Total Reward: 0.4987444281578064\n",
      "Episode 34.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 34.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 34.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 34.8 completed, Total Reward: 0.4987443685531616\n",
      "Episode 34.9 completed, Total Reward: 0.4987444281578064\n",
      "Episode 35.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 35.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 35.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 35.3 completed, Total Reward: 0.05854608863592148\n",
      "Episode 35.4 completed, Total Reward: 0.09954887628555298\n",
      "Episode 35.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 35.6 completed, Total Reward: 0.19919760525226593\n",
      "Episode 35.7 completed, Total Reward: 0.19919760525226593\n",
      "Episode 35.8 completed, Total Reward: 0.0360051691532135\n",
      "Episode 35.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 36.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 36.1 completed, Total Reward: 0.19919760525226593\n",
      "Episode 36.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 36.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 36.4 completed, Total Reward: 0.19919760525226593\n",
      "Episode 36.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 36.6 completed, Total Reward: 0.09954887628555298\n",
      "Episode 36.7 completed, Total Reward: 0.4987444281578064\n",
      "Episode 36.8 completed, Total Reward: 0.4987444281578064\n",
      "Episode 36.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 37.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 38.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 38.1 completed, Total Reward: 0.4987444281578064\n",
      "Episode 38.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 38.3 completed, Total Reward: 0.4987444281578064\n",
      "Episode 38.4 completed, Total Reward: 0.4987444281578064\n",
      "Episode 38.5 completed, Total Reward: 0.05854608863592148\n",
      "Episode 38.6 completed, Total Reward: 0.05854608863592148\n",
      "Episode 38.7 completed, Total Reward: 0.09954887628555298\n",
      "Episode 38.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 38.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 39.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 39.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 39.2 completed, Total Reward: 0.4987444281578064\n",
      "Episode 39.3 completed, Total Reward: 0.4992346465587616\n",
      "Episode 39.4 completed, Total Reward: 0.4987444281578064\n",
      "Episode 39.5 completed, Total Reward: 0.4987443685531616\n",
      "Episode 39.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 39.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 39.8 completed, Total Reward: 0.03867567703127861\n",
      "Episode 39.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 40.0 completed, Total Reward: 0.4987444281578064\n",
      "Episode 40.1 completed, Total Reward: 0.4987444281578064\n",
      "Episode 40.2 completed, Total Reward: 0.4987443685531616\n",
      "Episode 40.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 40.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 40.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 40.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 40.7 completed, Total Reward: 0.03867567703127861\n",
      "Episode 40.8 completed, Total Reward: 0.4987443685531616\n",
      "Episode 40.9 completed, Total Reward: 0.4987444281578064\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 41.0 completed, Total Reward: 0.4987444281578064\n",
      "Episode 41.1 completed, Total Reward: 0.4987443685531616\n",
      "Episode 41.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.5 completed, Total Reward: 0.19919760525226593\n",
      "Episode 41.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 41.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 42.0 completed, Total Reward: 0.19919760525226593\n",
      "Episode 42.1 completed, Total Reward: 0.19919760525226593\n",
      "Episode 42.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 42.3 completed, Total Reward: 0.09954888373613358\n",
      "Episode 42.4 completed, Total Reward: 0.05854608863592148\n",
      "Episode 42.5 completed, Total Reward: 0.09954887628555298\n",
      "Episode 42.6 completed, Total Reward: 0.09954887628555298\n",
      "Episode 42.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 42.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 42.9 completed, Total Reward: 0.19919762015342712\n",
      "Episode 43.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 43.1 completed, Total Reward: 0.4987443685531616\n",
      "Episode 43.2 completed, Total Reward: 0.4987444281578064\n",
      "Episode 43.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 43.4 failed, Total Reward: -1\n",
      "Episode 43.5 completed, Total Reward: 0.09954887628555298\n",
      "Episode 43.6 completed, Total Reward: 0.05854608863592148\n",
      "Episode 43.7 completed, Total Reward: 0.19434086978435516\n",
      "Episode 43.8 completed, Total Reward: 0.4987444281578064\n",
      "Episode 43.9 completed, Total Reward: 1.0\n",
      "Episode 44.0 completed, Total Reward: 1.0\n",
      "Episode 44.1 completed, Total Reward: 1.0\n",
      "Episode 44.2 completed, Total Reward: 0.4987444281578064\n",
      "Episode 44.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 44.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 44.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 44.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 44.7 completed, Total Reward: 0.4987443685531616\n",
      "Episode 44.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 44.9 completed, Total Reward: 0.4987443685531616\n",
      "Episode 45.0 completed, Total Reward: 1.0\n",
      "Episode 45.1 completed, Total Reward: 1.0\n",
      "Episode 45.2 completed, Total Reward: 0.03846153989434242\n",
      "Episode 45.3 completed, Total Reward: 0.03846153989434242\n",
      "Episode 45.4 completed, Total Reward: 0.03846153989434242\n",
      "Episode 45.5 completed, Total Reward: 0.05854608863592148\n",
      "Episode 45.6 completed, Total Reward: 0.038276225328445435\n",
      "Episode 45.7 failed, Total Reward: -1\n",
      "Episode 45.8 completed, Total Reward: 1.0\n",
      "Episode 45.9 completed, Total Reward: 1.0\n",
      "Episode 46.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 46.1 completed, Total Reward: 1.0\n",
      "Episode 46.2 completed, Total Reward: 0.4987443685531616\n",
      "Episode 46.3 completed, Total Reward: 0.4987444281578064\n",
      "Episode 46.4 completed, Total Reward: 0.19919762015342712\n",
      "Episode 46.5 completed, Total Reward: 1.0\n",
      "Episode 46.6 completed, Total Reward: 0.08637448400259018\n",
      "Episode 46.7 completed, Total Reward: 0.03846153989434242\n",
      "Episode 46.8 completed, Total Reward: 0.03809826076030731\n",
      "Episode 46.9 completed, Total Reward: 0.4987444281578064\n",
      "Episode 47.0 completed, Total Reward: 1.0\n",
      "Episode 47.1 failed, Total Reward: -1\n",
      "Episode 47.2 completed, Total Reward: 0.19919762015342712\n",
      "Episode 47.3 completed, Total Reward: 0.0360051691532135\n",
      "Episode 47.4 failed, Total Reward: -1\n",
      "Episode 47.5 completed, Total Reward: 1.0\n",
      "Episode 47.6 completed, Total Reward: 0.4987444281578064\n",
      "Episode 47.7 completed, Total Reward: 1.0\n",
      "Episode 47.8 completed, Total Reward: 0.4987443685531616\n",
      "Episode 47.9 completed, Total Reward: 0.4987444281578064\n",
      "Episode 48.0 completed, Total Reward: 0.03809826076030731\n",
      "Episode 48.1 completed, Total Reward: 0.49874311685562134\n",
      "Episode 48.2 completed, Total Reward: 1.0\n",
      "Episode 48.3 completed, Total Reward: 0.4987444281578064\n",
      "Episode 48.4 completed, Total Reward: 0.4987444281578064\n",
      "Episode 48.5 completed, Total Reward: 0.03867567703127861\n",
      "Episode 48.6 completed, Total Reward: 1.0\n",
      "Episode 48.7 completed, Total Reward: 0.0360051691532135\n",
      "Episode 48.8 failed, Total Reward: -1\n",
      "Episode 48.9 completed, Total Reward: 0.0360051691532135\n",
      "Episode 49.0 failed, Total Reward: -1\n",
      "Episode 49.1 completed, Total Reward: 1.0\n",
      "Episode 49.2 completed, Total Reward: 1.0\n",
      "Episode 49.3 completed, Total Reward: 1.0\n",
      "Episode 49.4 completed, Total Reward: 1.0\n",
      "Episode 49.5 completed, Total Reward: 1.0\n",
      "Episode 49.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 49.7 failed, Total Reward: -1\n",
      "Episode 49.8 completed, Total Reward: 0.4987443685531616\n",
      "Episode 49.9 completed, Total Reward: 0.4987443685531616\n",
      "Episode 50.0 completed, Total Reward: 0.4987444281578064\n",
      "Episode 50.1 completed, Total Reward: 0.4987444281578064\n",
      "Episode 50.2 completed, Total Reward: 1.0\n",
      "Episode 50.3 completed, Total Reward: 1.0\n",
      "Episode 50.4 completed, Total Reward: 1.0\n",
      "Episode 50.5 completed, Total Reward: 1.0\n",
      "Episode 50.6 completed, Total Reward: 1.0\n",
      "Episode 50.7 completed, Total Reward: 0.03809826076030731\n",
      "Episode 50.8 completed, Total Reward: 0.4987443685531616\n",
      "Episode 50.9 completed, Total Reward: 0.4987444281578064\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Episode 51.0 completed, Total Reward: 0.9627126455307007\n",
      "Episode 51.1 completed, Total Reward: 0.4987444281578064\n",
      "Episode 51.2 completed, Total Reward: 0.1991344541311264\n",
      "Episode 51.3 completed, Total Reward: 1.0\n",
      "Episode 51.4 completed, Total Reward: 1.0\n",
      "Episode 51.5 completed, Total Reward: 1.0\n",
      "Episode 51.6 completed, Total Reward: 0.4987444281578064\n",
      "Episode 51.7 completed, Total Reward: 1.0\n",
      "Episode 51.8 completed, Total Reward: 1.0\n",
      "Episode 51.9 completed, Total Reward: 0.05648985132575035\n",
      "Episode 52.0 completed, Total Reward: 0.4987444281578064\n",
      "Episode 52.1 completed, Total Reward: 1.0\n",
      "Episode 52.2 completed, Total Reward: 0.0360051691532135\n",
      "Episode 52.3 completed, Total Reward: 1.0\n",
      "Episode 52.4 completed, Total Reward: 1.0\n",
      "Episode 52.5 completed, Total Reward: 1.0\n",
      "Episode 52.6 completed, Total Reward: 1.0\n",
      "Episode 52.7 completed, Total Reward: 0.19574610888957977\n",
      "Episode 52.8 completed, Total Reward: 0.4987444281578064\n",
      "Episode 52.9 completed, Total Reward: 1.0\n",
      "Episode 53.0 completed, Total Reward: 1.0\n",
      "Episode 53.1 completed, Total Reward: 1.0\n",
      "Episode 53.2 completed, Total Reward: 1.0\n",
      "Episode 53.3 completed, Total Reward: 1.0\n",
      "Episode 53.4 completed, Total Reward: 1.0\n",
      "Episode 53.5 completed, Total Reward: 1.0\n",
      "Episode 53.6 completed, Total Reward: 1.0\n",
      "Episode 53.7 completed, Total Reward: 1.0\n",
      "Episode 53.8 completed, Total Reward: 1.0\n",
      "Episode 53.9 completed, Total Reward: 1.0\n",
      "Episode 54.0 completed, Total Reward: 1.0\n",
      "Episode 54.1 completed, Total Reward: 0.03867567703127861\n",
      "Episode 54.2 completed, Total Reward: 1.0\n",
      "Episode 54.3 completed, Total Reward: 1.0\n",
      "Episode 54.4 completed, Total Reward: 1.0\n",
      "Episode 54.5 completed, Total Reward: 0.0360051691532135\n",
      "Episode 54.6 completed, Total Reward: 1.0\n",
      "Episode 54.7 completed, Total Reward: 1.0\n",
      "Episode 54.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 54.9 completed, Total Reward: 1.0\n",
      "Episode 55.0 completed, Total Reward: 1.0\n",
      "Episode 55.1 completed, Total Reward: 1.0\n",
      "Episode 55.2 completed, Total Reward: 1.0\n",
      "Episode 55.3 completed, Total Reward: 0.4987443685531616\n",
      "Episode 55.4 completed, Total Reward: 1.0\n",
      "Episode 55.5 completed, Total Reward: 1.0\n",
      "Episode 55.6 completed, Total Reward: 0.4987444281578064\n",
      "Episode 55.7 completed, Total Reward: 1.0\n",
      "Episode 55.8 completed, Total Reward: 1.0\n",
      "Episode 55.9 completed, Total Reward: 0.34076380729675293\n",
      "Episode 56.0 completed, Total Reward: 1.0\n",
      "Episode 56.1 completed, Total Reward: 1.0\n",
      "Episode 56.2 completed, Total Reward: 1.0\n",
      "Episode 56.3 completed, Total Reward: 1.0\n",
      "Episode 56.4 completed, Total Reward: 1.0\n",
      "Episode 56.5 completed, Total Reward: 0.4987444281578064\n",
      "Episode 56.6 completed, Total Reward: 0.19903014600276947\n",
      "Episode 56.7 completed, Total Reward: 1.0\n",
      "Episode 56.8 completed, Total Reward: 0.19919760525226593\n",
      "Episode 56.9 completed, Total Reward: 1.0\n",
      "Episode 57.0 completed, Total Reward: 1.0\n",
      "Episode 57.1 completed, Total Reward: 1.0\n",
      "Episode 57.2 completed, Total Reward: 0.4987444281578064\n",
      "Episode 57.3 completed, Total Reward: 1.0\n",
      "Episode 57.4 completed, Total Reward: 1.0\n",
      "Episode 57.5 completed, Total Reward: 1.0\n",
      "Episode 57.6 failed, Total Reward: -1\n",
      "Episode 57.7 completed, Total Reward: 0.4987443685531616\n",
      "Episode 57.8 failed, Total Reward: -1\n",
      "Episode 57.9 failed, Total Reward: -1\n",
      "Episode 58.0 failed, Total Reward: -1\n",
      "Episode 58.1 completed, Total Reward: 1.0\n",
      "Episode 58.2 completed, Total Reward: 1.0\n",
      "Episode 58.3 completed, Total Reward: 0.19919762015342712\n",
      "Episode 58.4 completed, Total Reward: 1.0\n",
      "Episode 58.5 completed, Total Reward: 0.05648985132575035\n",
      "Episode 58.6 completed, Total Reward: 1.0\n",
      "Episode 58.7 completed, Total Reward: 0.4987444281578064\n",
      "Episode 58.8 completed, Total Reward: 1.0\n",
      "Episode 58.9 completed, Total Reward: 0.19919753074645996\n",
      "Episode 59.0 completed, Total Reward: 0.19919762015342712\n",
      "Episode 59.1 completed, Total Reward: 1.0\n",
      "Episode 59.2 completed, Total Reward: 1.0\n",
      "Episode 59.3 completed, Total Reward: 1.0\n",
      "Episode 59.4 completed, Total Reward: 1.0\n",
      "Episode 59.5 completed, Total Reward: 1.0\n",
      "Episode 59.6 completed, Total Reward: 1.0\n",
      "Episode 59.7 completed, Total Reward: 1.0\n",
      "Episode 59.8 completed, Total Reward: 1.0\n",
      "Episode 59.9 completed, Total Reward: 1.0\n",
      "Episode 60.0 completed, Total Reward: 0.49874430894851685\n",
      "Episode 60.1 completed, Total Reward: 0.19919762015342712\n",
      "Episode 60.2 completed, Total Reward: 1.0\n",
      "Episode 60.3 completed, Total Reward: 1.0\n",
      "Episode 60.4 completed, Total Reward: 1.0\n",
      "Episode 60.5 completed, Total Reward: 0.19919762015342712\n",
      "Episode 60.6 completed, Total Reward: 0.19919762015342712\n",
      "Episode 60.7 completed, Total Reward: 0.19919762015342712\n",
      "Episode 60.8 completed, Total Reward: 0.19919762015342712\n",
      "Episode 60.9 completed, Total Reward: 0.4987444281578064\n",
      "---------------------\n",
      "Evaluating...\n",
      "---------------------\n",
      "Found expression! Stopping early...\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(vocab_size, embedding_dim, hidden_dim, action_size)\n",
    "target_agent = DQNAgent(vocab_size, embedding_dim, hidden_dim, action_size)\n",
    "target_agent.load_state_dict(agent.state_dict())\n",
    "target_agent.eval()\n",
    "agent.train()\n",
    "\n",
    "optimizer = optim.Adam(agent.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "memory = ReplayBuffer(memory_capacity)\n",
    "\n",
    "epsilon = epsilon_start\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    episodes = []\n",
    "    for episode in range(num_episodes_per_batch):\n",
    "        state_symbols = env.reset()\n",
    "        state_encoded = encode_state(state_symbols)  # Shape: (seq_length,)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        transitions = []\n",
    "        i = 0\n",
    "\n",
    "        while not done and i < max_seq_length:\n",
    "            # Select action\n",
    "            action_idx = agent.act(state_encoded, epsilon)\n",
    "            action_symbol = action_symbols[action_idx]\n",
    "\n",
    "            try:\n",
    "                next_state_symbols, reward, done = env.step(action_symbol)\n",
    "            except ValueError as e:\n",
    "                reward = 0\n",
    "                done = True\n",
    "                next_state_symbols = state_symbols  # Remain in the same state\n",
    "\n",
    "            next_state_encoded = encode_state(next_state_symbols)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Store transition in memory\n",
    "            transitions.append((\n",
    "                state_encoded,\n",
    "                action_idx,\n",
    "                reward,\n",
    "                next_state_encoded,\n",
    "                done\n",
    "            ))\n",
    "\n",
    "            state_encoded = next_state_encoded\n",
    "            state_symbols = next_state_symbols\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        if not done:\n",
    "            total_reward = -1\n",
    "\n",
    "        episodes.append((transitions, total_reward))\n",
    "\n",
    "        total_rewards = [episode[1] for episode in episodes]\n",
    "\n",
    "        threshold = np.quantile(total_rewards, 1 - batch_quantile)\n",
    "\n",
    "        top_episodes = [episode for episode in episodes if episode[1] >= threshold]\n",
    "\n",
    "        for episode_transitions, _ in top_episodes:\n",
    "            for transition in episode_transitions:\n",
    "                memory.push(*transition)\n",
    "\n",
    "        # Experience replay\n",
    "        if len(memory) >= batch_size:\n",
    "            # Sample from memory\n",
    "            states_batch, actions_batch, rewards_batch, next_states_batch, dones_batch = memory.sample(batch_size)\n",
    "            # Compute current Q-values\n",
    "            q_values = agent(states_batch)\n",
    "            q_values = q_values.gather(1, actions_batch.unsqueeze(1)).squeeze(1)\n",
    "            # Compute target Q-values\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_agent(next_states_batch).max(dim=1)[0]\n",
    "                target_q_values = rewards_batch + gamma * next_q_values * (1 - dones_batch)\n",
    "            # Compute loss\n",
    "            loss = criterion(q_values, target_q_values)\n",
    "            # Optimize the model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Decay epsilon\n",
    "        if epsilon > epsilon_end:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "        # Update target network\n",
    "        if episode % target_update == 0:\n",
    "            target_agent.load_state_dict(agent.state_dict())\n",
    "\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episode {batch}.{episode} completed, Total Reward: {total_reward}\")\n",
    "        else:\n",
    "            print(f\"Episode {batch}.{episode} failed, Total Reward: {total_reward}\")\n",
    "\n",
    "    if batch % batch_eval == 0:\n",
    "        # Testing the agent\n",
    "        print('---------------------')\n",
    "        print('Evaluating...')\n",
    "        print('---------------------')\n",
    "        state_symbols = env.reset()\n",
    "        state_encoded = encode_state(state_symbols)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        expression_actions = []\n",
    "        i = 0\n",
    "        agent.eval()\n",
    "        \n",
    "        while not done and i < max_seq_length:\n",
    "            with torch.no_grad():\n",
    "                q_values = agent(state_encoded.unsqueeze(0))  # Add batch dimension\n",
    "                action_idx = torch.argmax(q_values).item()\n",
    "            action_symbol = action_symbols[action_idx]\n",
    "            expression_actions.append(action_symbol)\n",
    "            try:\n",
    "                next_state_symbols, reward, done = env.step(action_symbol)\n",
    "            except ValueError as e:\n",
    "                reward = -1.0\n",
    "                done = True\n",
    "                next_state_symbols = state_symbols\n",
    "            next_state_encoded = encode_state(next_state_symbols)\n",
    "            total_reward += reward\n",
    "            state_encoded = next_state_encoded\n",
    "            state_symbols = next_state_symbols\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        if done and total_reward == 1:\n",
    "            print('Found expression! Stopping early...')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Expression: + + X0 X0 5.0\n",
      "Test Total Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the agent\n",
    "state_symbols = env.reset()\n",
    "state_encoded = encode_state(state_symbols)\n",
    "done = False\n",
    "total_reward = 0\n",
    "expression_actions = []\n",
    "max_restart = 100\n",
    "r = 0\n",
    "i = 0\n",
    "\n",
    "agent.eval()\n",
    "target_agent.eval()\n",
    "\n",
    "while not done and r < max_restart:\n",
    "    with torch.no_grad():\n",
    "        q_values = agent(state_encoded.unsqueeze(0))  # Add batch dimension\n",
    "        action_idx = torch.argmax(q_values).item()\n",
    "    action_symbol = action_symbols[action_idx]\n",
    "    expression_actions.append(action_symbol)\n",
    "    \n",
    "    try:\n",
    "        next_state_symbols, reward, done = env.step(action_symbol)\n",
    "    except ValueError as e:\n",
    "        reward = -1.0\n",
    "        done = True\n",
    "        next_state_symbols = state_symbols\n",
    "\n",
    "    next_state_encoded = encode_state(next_state_symbols)\n",
    "    total_reward += reward\n",
    "    state_encoded = next_state_encoded\n",
    "    state_symbols = next_state_symbols\n",
    "\n",
    "    if i == max_seq_length:\n",
    "        state_symbols = env.reset()\n",
    "        state_encoded = encode_state(state_symbols)\n",
    "        total_reward = 0\n",
    "        expression_actions = []\n",
    "        i = 0\n",
    "        r += 1\n",
    "        print('restarting...')\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "\n",
    "n_const = env.expression.n_constants\n",
    "const_count = 0\n",
    "for idx, token in enumerate(expression_actions):\n",
    "    if const_count == n_const:\n",
    "        break\n",
    "    if token == 'C':\n",
    "        const_val = env.expression.optimized_constants[const_count].item()\n",
    "        expression_actions[idx] = str(round(const_val, 3))\n",
    "        const_count += 1\n",
    "\n",
    "print(f\"Constructed Expression: {' '.join(expression_actions)}\")\n",
    "print(f\"Test Total Reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
