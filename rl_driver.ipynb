{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from libs.srenv import SREnv\n",
    "from agents.rlagent import DQNAgent, ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = {\n",
    "    '+': 2,\n",
    "    '-': 2,\n",
    "    '*': 2,\n",
    "    '/': 2,\n",
    "    'C': 0  # Placeholder for constants\n",
    "}\n",
    "\n",
    "# Create your data and target tensors\n",
    "n_samples = 1000\n",
    "n_vars = 1\n",
    "\n",
    "for i in range(n_vars):\n",
    "    var_name = f'X{i}'\n",
    "    library[var_name] = 0\n",
    "\n",
    "# X0 = torch.randn(-10, 10, n_samples)\n",
    "# X1 = torch.linspace(-10, 10, n_samples)\n",
    "data = torch.randn([n_vars, n_samples]) * 20  # Shape: (n_vars, n_samples)\n",
    "target = 5 * data[0] - 10\n",
    "\n",
    "# Initialize the environment\n",
    "max_depth = 10\n",
    "env = SREnv(library=library, data=data, target=target, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.T.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary\n",
    "vocab = list(library.keys()) + ['PAD']\n",
    "symbol_to_index = {symbol: idx for idx, symbol in enumerate(vocab)}\n",
    "index_to_symbol = {idx: symbol for symbol, idx in symbol_to_index.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Maximum sequence length\n",
    "max_seq_length = max_depth\n",
    "\n",
    "def encode_state(state):\n",
    "    # Convert symbols to indices\n",
    "    state_indices = [symbol_to_index[symbol] for symbol in state]\n",
    "    # Pad sequence\n",
    "    if len(state_indices) < max_seq_length:\n",
    "        state_indices += [symbol_to_index['PAD']] * (max_seq_length - len(state_indices))\n",
    "    else:\n",
    "        state_indices = state_indices[:max_seq_length]\n",
    "    return torch.tensor(state_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_symbols = list(library.keys())\n",
    "action_size = len(action_symbols)\n",
    "symbol_to_action_idx = {symbol: idx for idx, symbol in enumerate(action_symbols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '-', '*', '/', 'C', 'X0']\n"
     ]
    }
   ],
   "source": [
    "print(action_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_episodes = 300\n",
    "batch_size = 32\n",
    "gamma = 0.9\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.1\n",
    "epsilon_decay = 0.995\n",
    "target_update = 50\n",
    "memory_capacity = 10000\n",
    "\n",
    "alpha = 1e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.T.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 failed, Total Reward: 0\n",
      "Episode 1 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 2 failed, Total Reward: 0\n",
      "Episode 3 failed, Total Reward: 0\n",
      "Episode 4 failed, Total Reward: 0\n",
      "Episode 5 failed, Total Reward: 0\n",
      "Episode 6 failed, Total Reward: 0\n",
      "Episode 7 failed, Total Reward: 0\n",
      "Episode 8 failed, Total Reward: 0\n",
      "Episode 9 failed, Total Reward: 0\n",
      "Episode 10 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 11 completed, Total Reward: 0.015459551475942135\n",
      "Episode 12 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 13 failed, Total Reward: 0\n",
      "Episode 14 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 15 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 16 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 17 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 18 failed, Total Reward: 0\n",
      "Episode 19 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 20 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 21 failed, Total Reward: 0\n",
      "Episode 22 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 23 failed, Total Reward: 0\n",
      "Episode 24 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 25 failed, Total Reward: 0\n",
      "Episode 26 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 27 failed, Total Reward: 0\n",
      "Episode 28 failed, Total Reward: 0\n",
      "Episode 29 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 30 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 31 failed, Total Reward: 0\n",
      "Episode 32 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 33 failed, Total Reward: 0\n",
      "Episode 34 failed, Total Reward: 0\n",
      "Episode 35 failed, Total Reward: 0\n",
      "Episode 36 completed, Total Reward: 7.095293403835967e-05\n",
      "Episode 37 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 38 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 39 failed, Total Reward: 0\n",
      "Episode 40 failed, Total Reward: 0\n",
      "Episode 41 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 42 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 43 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 44 completed, Total Reward: 0.009901623241603374\n",
      "Episode 45 failed, Total Reward: 0\n",
      "Episode 46 failed, Total Reward: 0\n",
      "Episode 47 failed, Total Reward: 0\n",
      "Episode 48 failed, Total Reward: 0\n",
      "Episode 49 failed, Total Reward: 0\n",
      "Episode 50 failed, Total Reward: 0\n",
      "Episode 51 completed, Total Reward: 0.00015962995530571789\n",
      "Episode 52 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 53 completed, Total Reward: 0.0002751803258433938\n",
      "Episode 54 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 55 failed, Total Reward: 0\n",
      "Episode 56 failed, Total Reward: 0\n",
      "Episode 57 failed, Total Reward: 0\n",
      "Episode 58 failed, Total Reward: 0\n",
      "Episode 59 failed, Total Reward: 0\n",
      "Episode 60 failed, Total Reward: 0\n",
      "Episode 61 failed, Total Reward: 0\n",
      "Episode 62 failed, Total Reward: 0\n",
      "Episode 63 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 64 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 65 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 66 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 67 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 68 failed, Total Reward: 0\n",
      "Episode 69 completed, Total Reward: 0.0002837513166014105\n",
      "Episode 70 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 71 failed, Total Reward: 0\n",
      "Episode 72 failed, Total Reward: 0\n",
      "Episode 73 failed, Total Reward: 0\n",
      "Episode 74 failed, Total Reward: 0\n",
      "Episode 75 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 76 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 77 failed, Total Reward: 0\n",
      "Episode 78 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 79 failed, Total Reward: 0\n",
      "Episode 80 failed, Total Reward: 0\n",
      "Episode 81 failed, Total Reward: 0\n",
      "Episode 82 failed, Total Reward: 0\n",
      "Episode 83 completed, Total Reward: 0.009901623241603374\n",
      "Episode 84 failed, Total Reward: 0\n",
      "Episode 85 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 86 failed, Total Reward: 0\n",
      "Episode 87 failed, Total Reward: 0\n",
      "Episode 88 failed, Total Reward: 0\n",
      "Episode 89 failed, Total Reward: 0\n",
      "Episode 90 failed, Total Reward: 0\n",
      "Episode 91 failed, Total Reward: 0\n",
      "Episode 92 failed, Total Reward: 0\n",
      "Episode 93 failed, Total Reward: 0\n",
      "Episode 94 failed, Total Reward: 0\n",
      "Episode 95 failed, Total Reward: 0\n",
      "Episode 96 failed, Total Reward: 0\n",
      "Episode 97 failed, Total Reward: 0\n",
      "Episode 98 failed, Total Reward: 0\n",
      "Episode 99 failed, Total Reward: 0\n",
      "Episode 100 failed, Total Reward: 0\n",
      "Episode 101 completed, Total Reward: 0.00010097483755089343\n",
      "Episode 102 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 103 failed, Total Reward: 0\n",
      "Episode 104 failed, Total Reward: 0\n",
      "Episode 105 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 106 failed, Total Reward: 0\n",
      "Episode 107 failed, Total Reward: 0\n",
      "Episode 108 failed, Total Reward: 0\n",
      "Episode 109 failed, Total Reward: 0\n",
      "Episode 110 failed, Total Reward: 0\n",
      "Episode 111 failed, Total Reward: 0\n",
      "Episode 112 failed, Total Reward: 0\n",
      "Episode 113 failed, Total Reward: 0\n",
      "Episode 114 failed, Total Reward: 0\n",
      "Episode 115 failed, Total Reward: 0\n",
      "Episode 116 failed, Total Reward: 0\n",
      "Episode 117 failed, Total Reward: 0\n",
      "Episode 118 failed, Total Reward: 0\n",
      "Episode 119 failed, Total Reward: 0\n",
      "Episode 120 failed, Total Reward: 0\n",
      "Episode 121 failed, Total Reward: 0\n",
      "Episode 122 failed, Total Reward: 0\n",
      "Episode 123 failed, Total Reward: 0\n",
      "Episode 124 failed, Total Reward: 0\n",
      "Episode 125 failed, Total Reward: 0\n",
      "Episode 126 failed, Total Reward: 0\n",
      "Episode 127 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 128 failed, Total Reward: 0\n",
      "Episode 129 failed, Total Reward: 0\n",
      "Episode 130 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 131 failed, Total Reward: 0\n",
      "Episode 132 failed, Total Reward: 0\n",
      "Episode 133 failed, Total Reward: 0\n",
      "Episode 134 failed, Total Reward: 0\n",
      "Episode 135 failed, Total Reward: 0\n",
      "Episode 136 failed, Total Reward: 0\n",
      "Episode 137 failed, Total Reward: 0\n",
      "Episode 138 failed, Total Reward: 0\n",
      "Episode 139 failed, Total Reward: 0\n",
      "Episode 140 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 141 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 142 failed, Total Reward: 0\n",
      "Episode 143 failed, Total Reward: 0\n",
      "Episode 144 failed, Total Reward: 0\n",
      "Episode 145 failed, Total Reward: 0\n",
      "Episode 146 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 147 failed, Total Reward: 0\n",
      "Episode 148 failed, Total Reward: 0\n",
      "Episode 149 failed, Total Reward: 0\n",
      "Episode 150 failed, Total Reward: 0\n",
      "Episode 151 failed, Total Reward: 0\n",
      "Episode 152 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 153 failed, Total Reward: 0\n",
      "Episode 154 failed, Total Reward: 0\n",
      "Episode 155 failed, Total Reward: 0\n",
      "Episode 156 completed, Total Reward: 0.0001009621046250686\n",
      "Episode 157 failed, Total Reward: 0\n",
      "Episode 158 failed, Total Reward: 0\n",
      "Episode 159 failed, Total Reward: 0\n",
      "Episode 160 failed, Total Reward: 0\n",
      "Episode 161 failed, Total Reward: 0\n",
      "Episode 162 failed, Total Reward: 0\n",
      "Episode 163 failed, Total Reward: 0\n",
      "Episode 164 failed, Total Reward: 0\n",
      "Episode 165 failed, Total Reward: 0\n",
      "Episode 166 completed, Total Reward: 0.00010096757614519447\n",
      "Episode 167 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 168 failed, Total Reward: 0\n",
      "Episode 169 failed, Total Reward: 0\n",
      "Episode 170 failed, Total Reward: 0\n",
      "Episode 171 failed, Total Reward: 0\n",
      "Episode 172 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 173 failed, Total Reward: 0\n",
      "Episode 174 failed, Total Reward: 0\n",
      "Episode 175 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 176 failed, Total Reward: 0\n",
      "Episode 177 failed, Total Reward: 0\n",
      "Episode 178 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 179 completed, Total Reward: 0.009901623241603374\n",
      "Episode 180 failed, Total Reward: 0\n",
      "Episode 181 failed, Total Reward: 0\n",
      "Episode 182 failed, Total Reward: 0\n",
      "Episode 183 failed, Total Reward: 0\n",
      "Episode 184 failed, Total Reward: 0\n",
      "Episode 185 failed, Total Reward: 0\n",
      "Episode 186 failed, Total Reward: 0\n",
      "Episode 187 failed, Total Reward: 0\n",
      "Episode 188 failed, Total Reward: 0\n",
      "Episode 189 failed, Total Reward: 0\n",
      "Episode 190 failed, Total Reward: 0\n",
      "Episode 191 failed, Total Reward: 0\n",
      "Episode 192 failed, Total Reward: 0\n",
      "Episode 193 failed, Total Reward: 0\n",
      "Episode 194 failed, Total Reward: 0\n",
      "Episode 195 failed, Total Reward: 0\n",
      "Episode 196 failed, Total Reward: 0\n",
      "Episode 197 failed, Total Reward: 0\n",
      "Episode 198 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 199 failed, Total Reward: 0\n",
      "Episode 200 failed, Total Reward: 0\n",
      "Episode 201 failed, Total Reward: 0\n",
      "Episode 202 failed, Total Reward: 0\n",
      "Episode 203 failed, Total Reward: 0\n",
      "Episode 204 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 205 failed, Total Reward: 0\n",
      "Episode 206 failed, Total Reward: 0\n",
      "Episode 207 failed, Total Reward: 0\n",
      "Episode 208 failed, Total Reward: 0\n",
      "Episode 209 failed, Total Reward: 0\n",
      "Episode 210 failed, Total Reward: 0\n",
      "Episode 211 failed, Total Reward: 0\n",
      "Episode 212 failed, Total Reward: 0\n",
      "Episode 213 failed, Total Reward: 0\n",
      "Episode 214 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 215 failed, Total Reward: 0\n",
      "Episode 216 failed, Total Reward: 0\n",
      "Episode 217 failed, Total Reward: 0\n",
      "Episode 218 failed, Total Reward: 0\n",
      "Episode 219 completed, Total Reward: 0.00010218506213277578\n",
      "Episode 220 failed, Total Reward: 0\n",
      "Episode 221 failed, Total Reward: 0\n",
      "Episode 222 failed, Total Reward: 0\n",
      "Episode 223 failed, Total Reward: 0\n",
      "Episode 224 failed, Total Reward: 0\n",
      "Episode 225 failed, Total Reward: 0\n",
      "Episode 226 failed, Total Reward: 0\n",
      "Episode 227 failed, Total Reward: 0\n",
      "Episode 228 failed, Total Reward: 0\n",
      "Episode 229 failed, Total Reward: 0\n",
      "Episode 230 failed, Total Reward: 0\n",
      "Episode 231 failed, Total Reward: 0\n",
      "Episode 232 failed, Total Reward: 0\n",
      "Episode 233 failed, Total Reward: 0\n",
      "Episode 234 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 235 failed, Total Reward: 0\n",
      "Episode 236 failed, Total Reward: 0\n",
      "Episode 237 failed, Total Reward: 0\n",
      "Episode 238 completed, Total Reward: 0.00010251496860291809\n",
      "Episode 239 failed, Total Reward: 0\n",
      "Episode 240 failed, Total Reward: 0\n",
      "Episode 241 completed, Total Reward: 0.00010096828191308305\n",
      "Episode 242 failed, Total Reward: 0\n",
      "Episode 243 failed, Total Reward: 0\n",
      "Episode 244 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 245 failed, Total Reward: 0\n",
      "Episode 246 completed, Total Reward: 0.00010096688492922112\n",
      "Episode 247 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 248 failed, Total Reward: 0\n",
      "Episode 249 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 250 failed, Total Reward: 0\n",
      "Episode 251 failed, Total Reward: 0\n",
      "Episode 252 failed, Total Reward: 0\n",
      "Episode 253 failed, Total Reward: 0\n",
      "Episode 254 failed, Total Reward: 0\n",
      "Episode 255 completed, Total Reward: 0.009901623241603374\n",
      "Episode 256 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 257 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 258 completed, Total Reward: 1.0\n",
      "Episode 259 completed, Total Reward: 0.00010108217975357547\n",
      "Episode 260 completed, Total Reward: 1.0\n",
      "Episode 261 completed, Total Reward: 0.00010252983338432387\n",
      "Episode 262 completed, Total Reward: 2.2271863144851523e-06\n",
      "Episode 263 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 264 failed, Total Reward: 0\n",
      "Episode 265 completed, Total Reward: 0.00010097483755089343\n",
      "Episode 266 completed, Total Reward: 0.0002837513166014105\n",
      "Episode 267 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 268 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 269 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 270 failed, Total Reward: 0\n",
      "Episode 271 failed, Total Reward: 0\n",
      "Episode 272 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 273 failed, Total Reward: 0\n",
      "Episode 274 completed, Total Reward: 0.009901623241603374\n",
      "Episode 275 failed, Total Reward: 0\n",
      "Episode 276 completed, Total Reward: 0.00010096690675709397\n",
      "Episode 277 failed, Total Reward: 0\n",
      "Episode 278 failed, Total Reward: 0\n",
      "Episode 279 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 280 completed, Total Reward: 1.0\n",
      "Episode 281 failed, Total Reward: 0\n",
      "Episode 282 completed, Total Reward: 0.009901623241603374\n",
      "Episode 283 failed, Total Reward: 0\n",
      "Episode 284 failed, Total Reward: 0\n",
      "Episode 285 failed, Total Reward: 0\n",
      "Episode 286 failed, Total Reward: 0\n",
      "Episode 287 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 288 failed, Total Reward: 0\n",
      "Episode 289 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 290 failed, Total Reward: 0\n",
      "Episode 291 completed, Total Reward: 0.00015679844364058226\n",
      "Episode 292 failed, Total Reward: 0\n",
      "Episode 293 completed, Total Reward: 1.0\n",
      "Episode 294 failed, Total Reward: 0\n",
      "Episode 295 failed, Total Reward: 0\n",
      "Episode 296 failed, Total Reward: 0\n",
      "Episode 297 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 298 completed, Total Reward: 0.00010216902592219412\n",
      "Episode 299 failed, Total Reward: 0\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(vocab_size, n_vars, embedding_dim, hidden_dim, action_size, max_seq_length=max_seq_length)\n",
    "target_agent = DQNAgent(vocab_size, n_vars, embedding_dim, hidden_dim, action_size, max_seq_length=max_seq_length)\n",
    "target_agent.load_state_dict(agent.state_dict())\n",
    "target_agent.eval()\n",
    "agent.train()\n",
    "\n",
    "optimizer = optim.Adam(agent.parameters(), lr=alpha)\n",
    "criterion = nn.MSELoss()\n",
    "memory = ReplayBuffer(memory_capacity)\n",
    "\n",
    "epsilon = epsilon_start\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state_symbols = env.reset()\n",
    "    state_encoded = encode_state(state_symbols).unsqueeze(0)  # Shape: (1, seq_length)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    i = 0\n",
    "\n",
    "    while not done and i < max_seq_length:\n",
    "        # Select action\n",
    "        action_idx = agent.act(data, state_encoded, epsilon)\n",
    "        action_symbol = action_symbols[action_idx]\n",
    "        \n",
    "        try:\n",
    "            next_state_symbols, reward, done = env.step(action_symbol)\n",
    "        except ValueError as e:\n",
    "            reward = 0\n",
    "            done = True\n",
    "            next_state_symbols = state_symbols  # Remain in the same state\n",
    "\n",
    "        next_state_encoded = encode_state(next_state_symbols).unsqueeze(0)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Store transition in memory\n",
    "        memory.push(\n",
    "            state_encoded,\n",
    "            action_idx,\n",
    "            reward,\n",
    "            next_state_encoded,\n",
    "            done\n",
    "        )\n",
    "\n",
    "        state_encoded = next_state_encoded\n",
    "        state_symbols = next_state_symbols\n",
    "\n",
    "        # Experience replay\n",
    "        if len(memory) >= batch_size:\n",
    "            # Sample from memory\n",
    "            states_batch, actions_batch, rewards_batch, next_states_batch, dones_batch = memory.sample(batch_size)\n",
    "            \n",
    "            # Compute current Q-values\n",
    "            q_values = agent(data, states_batch)\n",
    "            q_values = q_values.gather(1, actions_batch.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Compute target Q-values\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_agent(data, next_states_batch).max(dim=1)[0]\n",
    "                target_q_values = rewards_batch + gamma * next_q_values * (1 - dones_batch)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(q_values, target_q_values)\n",
    "            \n",
    "            # Optimize the model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    memory.prioritise(done)\n",
    "    \n",
    "    # Decay epsilon\n",
    "    if epsilon > epsilon_end:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Update target network\n",
    "    if episode % target_update == 0:\n",
    "        target_agent.load_state_dict(agent.state_dict())\n",
    "\n",
    "    if done:\n",
    "        print(f\"Episode {episode} completed, Total Reward: {total_reward}\")\n",
    "    else:\n",
    "        print(f\"Episode {episode} failed, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Expression: / / / / X0 X0 -1711.1744384765625 997.505126953125 -2932.523681640625\n",
      "Test Total Reward: 0.00010096690675709397\n"
     ]
    }
   ],
   "source": [
    "# Testing the agent\n",
    "state_symbols = env.reset()\n",
    "state_encoded = encode_state(state_symbols)\n",
    "done = False\n",
    "total_reward = 0\n",
    "expression_actions = []\n",
    "\n",
    "agent.eval()\n",
    "target_agent.eval()\n",
    "\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        q_values = agent(data, state_encoded.unsqueeze(0))  # Add batch dimension\n",
    "        action_idx = torch.argmax(q_values).item()\n",
    "    action_symbol = action_symbols[action_idx]\n",
    "    expression_actions.append(action_symbol)\n",
    "    \n",
    "    try:\n",
    "        next_state_symbols, reward, done = env.step(action_symbol)\n",
    "    except ValueError as e:\n",
    "        reward = -1.0\n",
    "        done = True\n",
    "        next_state_symbols = state_symbols\n",
    "\n",
    "    next_state_encoded = encode_state(next_state_symbols)\n",
    "    total_reward += reward\n",
    "    state_encoded = next_state_encoded\n",
    "    state_symbols = next_state_symbols\n",
    "\n",
    "n_const = env.expression.n_constants\n",
    "const_count = 0\n",
    "for idx, token in enumerate(expression_actions):\n",
    "    if const_count == n_const:\n",
    "        break\n",
    "    if token == 'C':\n",
    "        const_val = env.expression.optimized_constants[const_count].item()\n",
    "        expression_actions[idx] = str(const_val)\n",
    "        const_count += 1\n",
    "\n",
    "print(f\"Constructed Expression: {' '.join(expression_actions)}\")\n",
    "print(f\"Test Total Reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
